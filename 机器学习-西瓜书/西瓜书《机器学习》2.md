西瓜书《机器学习》

## 模型评估与选择

假设有m个样本，其中有a个样本分类错误。

错误率：分类错误的样本数占样本总数的比例，$E=a/m$。

精度：1-错误率，$1-a/m$。



误差：模型的实际预测输出与样本的真实输出之间的差异。

过拟合：模型在训练集上的误差很小，但在测试集上的误差却很大的现象。通常是因为模型学习能力过于强大，把训练集上的噪声也“记住”了。

欠拟合：模型在训练集上误差很大的现象。表明此时模型的学习能力低下。



测试样本通常不能出现在训练集中，防止测试的数据泄露给模型，从而导致测试集上的误差偏低，得到一个“过于乐观”的结果。



留出法（hold-out）：将数据集$D$划分为两个互斥的集合，其中一个集合作为训练集$S$，另一个作为测试集$T$。

注意：数据集划分的时候要尽可能保持数据分布的一致性，避免数据划分过程引入额外的偏差而对最终结果产生影响。

分层采样：数据集划分的过程中，保留类别比例的采样方式。比如让训练集和测试集中的男性数据与女性数据的比例保持1：1。

单次使用流出法得到的估计结果往往不够稳定可靠，在使用流出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为流出法的最终评估结果。例如使用10次流出法，每次数据的划分是随机的，这样得到的10个实验评估的结果，这10个结果的平均值即作为最终的评估结果。

数据集划分时，测试集过小会导致评估结果的方差偏大，训练集过小会导致模型训练结果不好。常见划分比例是，将大约$2/3\sim 4/5$的样本用于训练，剩余样本用于测试。



$k$折交叉验证法：先将数据集划分为$k$个份，保持每份数据的分布尽可能一致，每次取其中一个作为验证集，剩下$k-1$个作为训练集，这样会得到$k$个评估结果，用$k$个结果的均值作为当前模型泛化能力的衡量（估计）。

特别地，当数据集中有m个样本，使用m折交叉验证的情形，称为留一法（leave-one-out）。

因为留一法使用的训练集与初始数据集相比只少一个样本，因此留一法的评估结果往往被认为比较准确。但是当数据集比较大时，即m很大，这时候计算开销比较大。